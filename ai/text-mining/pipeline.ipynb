{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b25e14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: scikit-multilearn in ./.venv/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn scikit-multilearn nltk pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7dd2f4",
   "metadata": {},
   "source": [
    "**Carregar e Explorar os Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a87581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dataset/train.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832469b5",
   "metadata": {},
   "source": [
    "**Pré-processamento do Texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb57993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/andrels/projects/exercises/ai/text-\n",
      "[nltk_data]     mining/.venv/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andrels/projects/exercises/ai/text-\n",
      "[nltk_data]     mining/.venv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/andrels/projects/exercises/ai/text-\n",
      "[nltk_data]     mining/.venv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    explanation edits made username hardcore metal...\n",
       "1    daww matches background colour im seemingly st...\n",
       "2    hey man im really trying edit war guy constant...\n",
       "3    cant make real suggestions improvement wondere...\n",
       "4                  sir hero chance remember page thats\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "# Definir o diretório de dados do NLTK\n",
    "nltk_data_dir = os.path.join(os.getcwd(), \".venv\", \"nltk_data\")\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Baixar recursos do NLTK\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
    "nltk.download('stopwords', download_dir=nltk_data_dir)\n",
    "nltk.download('wordnet', download_dir=nltk_data_dir)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\t# Remover quebras de linha e espaços extras\n",
    "\ttext = text.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "\t# Remover URLs e menções\n",
    "\ttext = re.sub(r'http\\S+', '', text)\n",
    "\ttext = re.sub(r'@\\S+', '', text)\n",
    "\n",
    "\t# Remover caracteres especiais e números\n",
    "\ttext = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "\t# Converter para minúsculas\n",
    "\ttext = text.lower()\n",
    "\n",
    "\t# Tokenização\n",
    "\ttokens = word_tokenize(text)\n",
    "\n",
    "\t# Remover stopwords\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "\t# # Lemmatização\n",
    "\t# lemmatizer = WordNetLemmatizer()\n",
    "\t# tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "\treturn ' '.join(tokens)\n",
    "\n",
    "data['comment_text'] = data['comment_text'].apply(preprocess_text)\n",
    "data['comment_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6ddec",
   "metadata": {},
   "source": [
    "**Train e Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f9c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\tdata['comment_text'],\n",
    "\tdata.drop(columns=['id', 'comment_text']),\n",
    "\ttest_size=0.3,\n",
    "\trandom_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ffde6",
   "metadata": {},
   "source": [
    "**Vetorização dos Textos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b3f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vetorização dos textos\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba17ee",
   "metadata": {},
   "source": [
    "**Treinamento com Classificação Multirrótulo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bbf8e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.8640332553475936\n",
      "Hamming Loss:  0.0353442513368984\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.61      0.85      0.71      4582\n",
      " severe_toxic       0.26      0.86      0.40       486\n",
      "      obscene       0.65      0.88      0.75      2556\n",
      "       threat       0.19      0.75      0.30       136\n",
      "       insult       0.51      0.87      0.65      2389\n",
      "identity_hate       0.20      0.78      0.32       432\n",
      "\n",
      "    micro avg       0.51      0.86      0.64     10581\n",
      "    macro avg       0.40      0.83      0.52     10581\n",
      " weighted avg       0.56      0.86      0.67     10581\n",
      "  samples avg       0.06      0.08      0.07     10581\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrels/projects/exercises/ai/text-mining/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/andrels/projects/exercises/ai/text-mining/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/andrels/projects/exercises/ai/text-mining/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, classification_report\n",
    "model = OneVsRestClassifier(LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=300,\n",
    "    solver='liblinear'  # mais leve\n",
    "))\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Avaliar o desempenho\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Hamming Loss: \", hamming_loss(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=y_train.columns))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
